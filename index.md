---
layout: homepage
---

## About Me

(migrating not finished)

I am currently a Ph.D. student at UCLA advised by Prof. [Cho-Jui Hsieh](http://web.cs.ucla.edu/~chohsieh/) and a continuing Student Researcher at Google working on text-based generative models (previously [Boqing Gong](https://scholar.google.com/citations?user=lv9ZeVUAAAAJ&hl=en) and [Ting Liu](https://research.google/people/105496/).
My research area is Efficient and Automated Methods for Machine Learning (AIGC, AutoML, Dataset).
I was the recepient of the **Outstanding Paper Award** at ICLR 2021.
Besides research, I am also open to venture capital and entrepreneurial opportunities.

I obtained my B.S. degree (dual) in Computer Science and Statistics from the University of Michigan, with the highest distinction.
During this period, I interned at [Microsoft Research](https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/) and [Sensetime](https://www.sensetime.com/en) on machine learning and computer vision, as well as helped a startup to develop its prototype robots.
Prior to that, I worked on quantitative investing at Shanghai Key Laboratory of Finance.


## Research Overview

I study the problem of **AI for AI**.
The goal is to leverage the power of AI agents to automatize the development of itself.
For the past years, I have mainly focused on the following areas:
- **Automated Methods for Multimodal Language Agents (Current)** <br/>
e.g. [[MoP]()] [[DPO-Diff]()]
- **Dataset Compression (DD/DC)** <br/>
e.g. [[TESLA](https://arxiv.org/abs/2211.10586)] [[DC-BENCH](https://dc-bench.github.io/)] [[FedDM](https://arxiv.org/abs/2207.09653)]
- **Optimizer Search (OS)** <br/>
e.g. [[ENOS](https://arxiv.org/abs/2209.13575)]
- **Neural Architecture Search (NAS)** <br/>
e.g. [[DARTS-PT](https://arxiv.org/abs/2108.04392)] [[DrNAS](https://arxiv.org/abs/2006.10355)] [[GM-NAS](https://arxiv.org/abs/2203.15207)]


## Outreach

- **VC/Startups** I've been interviewing for VC positions. If you are in VC/Startup business and for any reason is looking for people with domain knowledge in A.I., I'd be delighted to have a chat with you.
- **Prospective Students** I am currently forming a Research Alliance to pursue topics in large-scale text-based generative models (LLMs, Diffusion Models). As part of this endeavor, I will no longer advise interns on my own; Instead, qualified students will be joining this team and under the direct supervision of Prof. [Cho-Jui Hsieh](http://web.cs.ucla.edu/~chohsieh/), Prof. [Tianyi Zhou](https://tianyizhou.github.io/), Prof. [Minhao Cheng](https://cmhcbb.github.io/) and myself. For more information on the management, please refer to this temporary onboarding [slides](https://docs.google.com/presentation/d/1PtRwK6KuqNhExz_ouiu1UDva5Fw6R7PuvrxsVCzSA9U/edit?usp=sharing). If you are interested, please send an application to [my email](ruocwang@g.ucla.edu) and include your resume, publication record (working-in progress papers are fine), and 1-2 paragraph explaining your area of interests in AIGC.


## News

- **[Oct. 2023]** I will return to Google Research, focusing on advancing the state of Large Language Models.
- **[Aug. 2023]** I formed a Research Alliance to pursue topics in AIGC (see the Outreach section for more info).
- **[Apr. 2023]** [TESLA](https://arxiv.org/abs/2211.10586) is accepted at ICML 2023 - one of the first to scale-up Dataset Distillation to ImageNet-1K.
- **[Mar. 2023]** [FedDM](https://arxiv.org/abs/2207.09653) is accepted at CVPR 2023.
- **[Sep. 2022]** Two papers accepted at NeurIPS 2022.
- **[Jul. 2022]** We released [DC-BENCH](https://justincui03.github.io/dcbench/) - the first benchmark for evaluating Dataset Compression methods.
- **[May. 2022]** I started my internship at Google Research, hosted by [Boqing Gong](http://boqinggong.info/) and [Ting Liu](http://www.tliu.org/).
- [May 2022] I received Outstanding Graduate Student Award for the Master's degree at UCLA.
- **[Jan. 2022]** Two papers accepted at ICLR 2022.
- **[Jul. 2021]** One paper accepted at ICCV 2021.
- **[Apr. 2021]** Our paper *"Rethinking Architecture Selection in Differentiable NAS"* won the <span style="color:red">**Outstanding Paper Award**</span> at ICLR 2021.
- **[Jan. 2021]** Two papers accepted at ICLR 2021.


## Industrial Experiences (Selected)

- **Google Research** (2023 - Present)<br/>
Large Language Models
- **Google Research** (2022 - 2023)<br/>
Text-to-Image Diffusion Models, Eficient Transformers
- **Microsoft Research Asia** (2019)<br/>
Neural Architecture Search
  

{% include_relative _includes/publications.md %}

<!-- {% include_relative _includes/services.md %} -->